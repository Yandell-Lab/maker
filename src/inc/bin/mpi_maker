#!\usr\bin\perl

use warnings;
use strict "vars";
use strict "refs";

use FindBin;
use lib "$FindBin::Bin/../lib";
use lib "$FindBin::Bin/../perl/lib";
use vars qw($RANK $LOG @CMD_ARGS $VERSION);
use Storable qw(freeze thaw);
use Config;

BEGIN{
   $VERSION = '2.07';

   if (not ($ENV{CGL_SO_SOURCE})) {
      $ENV{CGL_SO_SOURCE} = "$FindBin::Bin/../lib/CGL/so.obo";
   }
   if (not ($ENV{CGL_GO_SOURCE})) {
      $ENV{CGL_GO_SOURCE} = "$FindBin::Bin/../lib/CGL/gene_ontology.obo"
   }

   @CMD_ARGS = @ARGV;

   #what to do on ^C
   $SIG{'INT'} = sub {
      print STDERR "\n\nMaker aborted by user!!\n\n";
      exit (1);
   };

   #supress warnings from storable module
   $SIG{'__WARN__'} = sub {
      warn $_[0] if ( $_[0] !~ /Not a CODE reference/ &&
		      $_[0] !~ /Can\'t store item CODE/ &&
		      $_[0] !~ /Find\:\:skip_pattern|File\/Find\.pm/
		    );
   };

   #output to log file of seq that caused rank to die
   $SIG{'__DIE__'} =
   sub {
      if (defined ($LOG) && defined $_[0]) {
	 my $die_count = $LOG->get_die_count();
	 $die_count++;

	 $LOG->add_entry("DIED","RANK",$RANK);
	 $LOG->add_entry("DIED","COUNT",$die_count);
      }

      die $_[0]."\n".
	  "FATAL ERROR\n";
   };
}

use Cwd;
use Storable;
use FileHandle;
use File::Path;
use Getopt::Long qw(:config no_ignore_case);
use File::Temp qw(tempfile tempdir);
use Bio::DB::Fasta;
use GI;
use Dumper::GFF::GFFV3;
use Iterator::Any;
use Iterator::Fasta;
use Iterator::GFF3;
use Fasta;
use FastaChunker;
use maker::auto_annotator;
use cluster;
use repeat_mask_seq;
use runlog;
use ds_utility;
use GFFDB;
use Error qw(:try);
use Error::Simple;
use Process::MpiChunk;
use Process::MpiTiers;
use Parallel::MPIcar qw(:all);


#--MPI_Init requires there to be arguments on @ARGV
#--This is a logic problem by the Package Authors
#--This is a hack to solve the problem
if (not @ARGV) {
   push (@ARGV, 'null');
   MPI_Init();			#initiate the MPI
   shift @ARGV;
}
else {
   MPI_Init();			#initiate the MPI
}

select((select(STDOUT), $|=1)[0]); #make STDOUT buffer flush immediately

my $usage = "
Usage:

     mpi_maker [options] <maker_opts> <maker_bopts> <maker_exe>

     Maker is a program that produces gene annotations in GFF3 file format using
     evidence such as EST alignments and protein homology.  Maker can be used to
     produce gene annotations for new genomes as well as update annotations from
     existing genome databases.

     The three input arguments are user control files that specify how maker
     should behave. All options for maker should be set in the control files,
     but a few can also be set on the command line. Command line options provide
     a convenient machanism to override commonly altered control file values.

     Input files listed in the control options files must be in fasta format
     unless otherwise specified. Please see maker documentation to learn more
     about control file  configuration.  Maker will automatically try and locate
     the user control files in the current working directory if these arguments
     are not supplied when initializing maker.

     It is important to note that maker does not try and recalculated data that
     it has already calculated.  For example, if you run an analysis twice on
     the same dataset file you will notice that maker does not rerun any of the
     blast analyses, but instead uses the blast analyses stored from the
     previous run.  To force maker to rerun all analyses, use the -f flag.


Options:

     -genome|g <filename> Specify the genome file.

     -predictor|p <type>  Selects the predictor(s) to use when building
                          annotations.  Defines a pool of gene models for
                          annotation selection.

                          types: snap
                                 augustus
                                 fgenesh
                                 genemark
                                 est2genome (Uses EST's directly)
                                 protein2genome (For Prokaryotic annotation only)
                                 model_gff (Pass through GFF3 annotations)
                                 pred_gff (Uses passed through GFF3 predictions)

                          Use a ',' to separate types (nospaces)
                          i.e. -predictor=snap,augustus,fgenesh

     -RM_off|R           Turns all repeat masking off.

     -datastore/         Forcably turn on/off MAKER's use of a two deep datastore
      nodatastore        directory structure for output.  By default this option
                         turns on whenever there are more the 1,000 contigs in
                         the input genome fasta file.

     -base    <string>   Set the base name MAKER uses to save output files.
                         MAKER uses the input genome file name by default.

     -retry|r <integer>  Rerun failed contigs up to the specified count.

     -cpus|c  <integer>  Tells how many cpus to use for BLAST analysis.

     -force|f            Forces maker to delete old files before running again.
			 This will require all blast analyses to be rerun.

     -again|a            Caculate all annotations and output files again even if
			 no settings have changed. Does not delete old analyses.

     -evaluate|e         Run Evaluator on final annotations (under development).

     -quiet|q            Silences most of maker's status messages.

     -qq                 Really quit. Silences everything but major errors.

     -CTL                Generate empty control files in the current directory.

     -help|?             Prints this usage statement.


";

#-------------------------------------------------------------------------------
#------------------------------------ MAIN -------------------------------------
#-------------------------------------------------------------------------------

#--set object variables for serialization of data
$Storable::forgive_me = 1; #allows serializaion of objects with code refs

#------INITIATE MPI VARIABLES------
my $rank = MPI_Comm_rank(MPI_COMM_WORLD); #my proccess number
my $size = MPI_Comm_size(MPI_COMM_WORLD); #how many proccesses
$RANK = $rank;

#MPI SIGNAL CODES
#--mpi message tags
my $who_I_am       = 1111;
my $what_I_want    = 2222;
my $result_status  = 3333;
my $request_status = 4444;
my $c_res_status   = 5555;
my $chunk_status   = 6666;
my $work_order     = 7777; #generic data tag
my $mpi_data       = 8888;
my $message_length = 9999;

#--what_I_want type signals
my $need_tier   = 1;
my $need_helper = 2;
my $have_c_res  = 3;
my $need_c_res  = 4;

#--request_status signals
my $wait_as_helper = 1;
my $yes_tier       = 2;
my $yes_helper     = 3;
my $no_helper      = 4;
my $go_chunk       = 5;
my $reset          = 6;
my $wait_ask_again = 7;
my $terminate      = 0;

#--results_status signals
my $yes_result = 1;
my $no_result  = 0;

#--c_res_status signal
my $yes_c_res      = 1;
my $no_c_res      = 0;

#--chunk_status signals
my $yes_chunk = 1;
my $no_chunk  = 0;

#---variables for thread and the root node
my @c_results;
my @failed;
my @interrupted;
my @res_loc;
my @limbo_stack;
my @active;
my @chunks;
my @returned_chunks;
my $t_need_flag;
my $t_tier;
my $t_tier_result;
my $t_chunk;
my $t_chunk_result;
my $t_terminate;
my $empty;

#---global variables
my %OPT;
my $root = 0; #define root node (only changed for debugging)

#---Process options on the command line
try{
    GetOptions("RM_off|R" => \$OPT{R},
	       "force|f" => \$OPT{force},
	       "genome|g=s" => \$OPT{genome},
	       "cpus|c=i" => \$OPT{cpus},
	       "predictor=s" =>\$OPT{predictor},
	       "retry=i" =>\$OPT{retry},
	       "evaluate" =>\$OPT{evaluate},
	       "again|a" =>\$OPT{again},
	       "quiet|q" =>\$main::quiet,
	       "qq"    =>\$main::qq,
               "check" =>\$OPT{check},
               "base=s" =>\$OPT{out_name},
               "datastore!" =>\$OPT{datastore},
	       "fast" => \$OPT{fast},
	       "dtmp" => \$main::dtmp,
	       "debug" => \$main::debug,
               "MWAS=s" =>sub {exec("$FindBin::Bin/../MWAS/bin/mwas_server $_[1]")},
	       "no_threads" =>\$main::no_threads, #for debugging
	       "CTL" => sub {GI::generate_control_files() if($rank == $root); MPI_Finalize(); exit(0);},
	       "version" => sub{print "$VERSION\n" if($rank == $root); MPI_Finalize(); exit(0)},
	       "help|?" => sub {print $usage if($rank == $root); MPI_Finalize(); exit(0)}
	       );

    $main::quiet = 1 if($main::qq);
    $main::no_threads = 1 if(!$Config::Config{useithreads});
}
catch Error::Simple with{
    my $E = shift;

    print STDERR $E->{-text};
    die "\n\nMaker failed parsing command line options!!\n\n";
};

#---set up thread support
unless($main::no_threads){
    require threads;
    require threads::shared;
    threads::shared->import();

    unless($threads::VERSION >= 1.67){
	die "mpi_maker requires threads version 1.67 or greater\n",
	"You have version ". $threads::VERSION ."\n";
    }

    #--change signal handling for threads
    #what to do on ^C
    $SIG{'INT'} = sub {
	print STDERR "\n\nMaker aborted by user!!\n\n";
	unless($main::no_threads){
	    my @threads = threads->list();
	    foreach my $thr (@threads){
		$thr->detach;
	    }
	}
	exit (1);
    };

   #output to log file of seq that caused rank to die
   $SIG{'__DIE__'} = sub {
       if (defined ($LOG) && defined $_[0]) {
	   my $die_count = $LOG->get_die_count();
	   $die_count++;
	   
	   $LOG->add_entry("DIED","RANK",$RANK);
	   $LOG->add_entry("DIED","COUNT",$die_count);
       }
       
       my @threads = threads->list();
       foreach my $thr (@threads){
	   $thr->detach;
       }
       
       die $_[0]."\n".
	   "FATAL ERROR\n";
   };

    #set up sharing
    share(\@chunks);
    share(\@returned_chunks);
    share(\$t_need_flag);
    share(\$t_tier);
    share(\$t_tier_result);
    share(\$t_chunk);
    share(\$t_chunk_result);
    share(\$t_terminate);
}
else{
    $main::no_threads = 1;
}

#--exec regular maker if no-threads and size of 1
if($size == 1 && ! $main::debug){
    exec("$FindBin::Bin/maker", @CMD_ARGS);
}
	


#--------------------------------------
#---------PRIMARY MPI PROCCESS---------
#--------------------------------------

#--check if root node
if ($rank == $root) {
    #varibles that are persistent outside of try
    my %CTL_OPT;
    my $iterator;
    my $DS_CTL;
    my $GFF_DB;
    my $build;
    
    try{
	#get arguments off the command line
	my @ctlfiles = @ARGV;
	
	if (not @ctlfiles) {
	    if (-e "maker_opts.ctl" &&
		-e "maker_bopts.ctl" &&
		-e "maker_exe.ctl"
		) {
		
		@ctlfiles = ("maker_opts.ctl",
			     "maker_bopts.ctl",
			     "maker_exe.ctl"
			     );
	    }
	    else {
		print STDERR  "ERROR: Control files not found\n";
		print $usage;
		exit(0);
	    }
	}

	#--Control file processing
	
	#set up control options from control files
	%CTL_OPT = GI::load_control_files(\@ctlfiles, \%OPT, $size);

	#--send control files to all nodes
	for(my $i = 1; $i < $size; $i++){
	    my $data = \%CTL_OPT;
	    print "INITIALIZE CTL_OPT\t|  SND2\t|  mpi_data (ctl_opt)\t|  $rank\t-->\t$i\n" if($main::debug);
	    MPI_SendII(\$data, $i, $mpi_data, MPI_COMM_WORLD);
	}

	#---set up blast databases and indexes for analyisis
	if($size > 1){
	    GI::create_blastdb(\%CTL_OPT);
	    GI::build_all_indexes(\%CTL_OPT);
	}

	#--open datastructure controller
	$DS_CTL = ds_utility->new(\%CTL_OPT);
	
	#--set up gff database
	$GFF_DB = new GFFDB(\%CTL_OPT);
	$build = $GFF_DB->next_build;
	
	#---load genome multifasta/GFF3 file
	$iterator = new Iterator::Any( -fasta => $CTL_OPT{'genome'},
				       -gff => $CTL_OPT{'genome_gff'},
				       );
	$iterator->step($CTL_OPT{'_step'});
    }
    catch Error::Simple with{
	my $E = shift;
	print STDERR $E->{-text};
	
	my $code = 2;
	$code = $E->{-value} if (defined($E->{-value}));
	
	exit($code);
    };
    
    #====MPI COMMUNICATION    
    #---main code for distribution of mpi data starts here    

    #thread for root node to do other things than just manage mpi
    $t_need_flag = ($main::no_threads) ? 0 : 1; #set to true for threads false for no threads
    my $thr = threads->create(\&node_thread) if($t_need_flag);

    my $go_mpi_status = 1;
    
    while($go_mpi_status){
	#====INTERNAL TIER THREAD
	#check on results from internal thread
	if (defined($t_tier_result)){
	    my $t_res = ${thaw($t_tier_result)};
	    $t_tier_result = undef;
	    $active[$root] = 0;

	    push(@failed, $t_res->{-fasta}) if ($t_res->{-failed});
	    push(@interrupted, $t_res->{-fasta}) if ($t_res->{-interrupt});
	}
	if (defined($t_chunk_result)){
	    my $chunk =  ${thaw($t_chunk_result)};
	    $t_chunk_result = undef;
	    my $id = $chunk->id();
	    ($id) = split (":", $id);
	    push (@{$c_results[$id]}, $chunk);
	    unshift (@{$res_loc[$id]}, $root);
	}
	
	#see if there are chunks to get from the internal thread
	while((@limbo_stack > 0) && (@chunks > 0) && (my $chunk = shift @chunks)){
	    my $helper = shift @limbo_stack;
	    $active[$helper] = -1 - $root; #who node now works for
	    #turn node into helper node
	    print "HELPER/RESULT REQUESTED\t|  RECV\t|  who_I_am (clr thread)\t\t|  $rank\t<--\t$helper\n" if($main::debug);
	    MPI_Recv(\$empty, 1,  MPI_INT, $helper, $who_I_am, MPI_COMM_WORLD); #clear who I am response
	    print "HELPER/RESULT REQUESTED\t|  RECV\t|  what_I_want (clr thread)\t|  $rank\t<--\t$helper\n" if($main::debug);
	    MPI_Recv(\$empty, 1, MPI_INT, $helper, $what_I_want, MPI_COMM_WORLD); #clear what I want response
	    print "HELPER/RESULT REQUESTED\t|  RECV\t|  result_status (clr thread)\t|  $rank\t<--\t$helper\n" if($main::debug);
	    MPI_Recv(\$empty, 1,  MPI_INT, $helper, $result_status, MPI_COMM_WORLD); #clear result status response
	    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (wait_as_helper thread)\t|  $rank\t-->\t$helper\n" if($main::debug);
	    MPI_Send(\$wait_as_helper, 1, MPI_INT, $helper, $request_status, MPI_COMM_WORLD); #signal to become helper

	    #send chunk to helper
	    print "HELPER/RESULT REQUESTED\t|  SEND\t|  who_I_am (from thread)\t|  $rank\t-->\t$helper\n" if($main::debug);
	    MPI_Send(\$root, 1,  MPI_INT, $helper, $who_I_am, MPI_COMM_WORLD); #tell helper node I need help
	    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (go_chunk from thread)\t|  $rank\t-->\t$helper\n" if($main::debug);
	    MPI_Send(\$go_chunk, 1, MPI_INT, $helper, $request_status, MPI_COMM_WORLD ); #tell helper node a chunk is coming
	    print "HELPER/RESULT REQUESTED\t|  SND2\t|  mpi_data (chunk from thread)\t|  $rank\t-->\t$helper\n" if($main::debug);
	    MPI_SendII(\$chunk, $helper, $mpi_data, MPI_COMM_WORLD, 1); #send the chunk
	}
	
	#get tier for internal thread
	if($t_need_flag > 0){
	    my $tier;
	    my $f_count = @failed;
	    my $i_count = @interrupted;

	    #as of 12/15/2010 threads will process only chunks and not tiers
	    #uncomment this while statement to change that behavior
	    #while (my $fasta = $iterator->nextFasta() || shift @failed || shift @interrupted){
	    #    $tier = Process::MpiTiers->new({fasta => $fasta,
	    #    				CTL_OPT => \%CTL_OPT,
	    #    				DS_CTL  => $DS_CTL,
	    #    				GFF_DB  => $GFF_DB,
	    #    				build   => $build},
	    #    			       $root,
	    #    			       'Process::MpiChunk'
	    #    			       );
	    #
	    #    last if(! $tier->terminated);
	    #}
	    
	    $tier->{_seen}++ if($i_count != @interrupted); #tag tier (easy to do it this way)
	    
	    #take a short break before processing failed contigs
	    #this handles heavy processor usage when failure is related
	    #to maker process overlap
	    sleep 1 if($f_count != @failed);

	    if(defined $tier && ! $tier->terminated){
		$t_need_flag = 0;
		my $t_val = freeze(\$tier);
		$t_tier = $t_val;
		$active[$root] = 1;
	    }
	    else{
		$t_need_flag = 2; #take tier or chunk
		$active[$root] = 0;
	    }
	}

	if($size > 1){
	    #work with mpi nodes now
	    my $who;
	    my $what;
	    my $rs_type;
	    
	    #see who asks for a file
	    print "COMM INITIALIZATION\t|  RECV\t|  who_I_am\t\t\t|  $rank\t<--\tANY\n" if($main::debug);
	    MPI_Recv(\$who, 1,  MPI_INT, -2, $who_I_am, MPI_COMM_WORLD);
	    
	    #see what the mpi node wants
	    print "COMM INITIALIZATION\t|  RECV\t|  what_I_want\t\t\t|  $rank\t<--\t$who\n" if($main::debug);
	    MPI_Recv(\$what, 1, MPI_INT, $who, $what_I_want, MPI_COMM_WORLD);
    
	    #if the node wants a tier to process, do this
	    if($what == $need_tier){
		#receive result status
		print "COMM TIER REQUESTED\t|  RECV\t|  result_status (is result?)\t|  $rank\t<--\t$who\n" if($main::debug);
		MPI_Recv(\$rs_type, 1,  MPI_INT, $who, $result_status, MPI_COMM_WORLD);
		
		#get result if available
		if($rs_type == $yes_result){
		    my $result;
		    print "COMM TIER REQUESTED\t|  RECV\t|  mpi_data (tier_result)\t|  $rank\t<--\t$who\n" if($main::debug);
		    MPI_RecvII(\$result, $who, $mpi_data, MPI_COMM_WORLD);
		    push(@failed, $result->{-fasta}) if ($result->{-failed});
		    push(@interrupted, $result->{-fasta}) if ($result->{-interrupt});
		}
		
		#if a contig is available send tier
		my $tier;
		my $f_count = @failed;
		my $i_count = @interrupted;
		while (my $fasta = $iterator->nextFasta() || shift @failed || shift @interrupted){
		    $tier = Process::MpiTiers->new({fasta => $fasta,
						    CTL_OPT => \%CTL_OPT,
						    DS_CTL  => $DS_CTL,
						    GFF_DB  => $GFF_DB,
						    build   => $build},
						   $who,
						   'Process::MpiChunk'
						   );
		    
		    last if(! $tier->terminated);
		}
		
		$tier->{_seen}++ if($i_count != @interrupted); #tag tier (easy to do it this way)		
		
		#take a short break before processing failed contigs
		#this handles heavy processor usage when failure is related
		#to maker process overlap
		sleep 1 if($f_count != @failed);
		
		if(defined $tier && ! $tier->terminated){
		    #say tier is available and send it
		    print "COMM TIER REQUESTED\t|  SEND\t|  req_stat (yes_tier)\t\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$yes_tier, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD);
		    print "COMM TIER REQUESTED\t|  SND2\t|  mpi_data (tier)\t\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_SendII(\$tier, $who, $mpi_data, MPI_COMM_WORLD);
		    @limbo_stack = grep {$_ != $who} @limbo_stack if(defined($active[$who]) && $active[$who] == 0);
		    $active[$who] = 1;
		}
		else{
		    print "COMM TIER REQUESTED\t|  SEND\t|  req_stat (wait_ask_again)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$wait_ask_again, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD);
		    push(@limbo_stack, $who) if(!defined($active[$who]) || $active[$who]);
		    $active[$who] = 0;
		}
	    }
	    #if the node wants a helper or needs a chunk result, do this
	    elsif($what == $need_helper || $what == $need_c_res){
		#--first send c_res_status
		# send ids of nodes with chunk results
		if(defined ($res_loc[$who])){
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  c_res_status (yes_c_res)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$yes_c_res, 1, MPI_INT, $who, $c_res_status, MPI_COMM_WORLD);
		    print "HELPER/RESULT REQUESTED\t|  SND2\t|  mpi_data (result_loc_list)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_SendII(\$res_loc[$who], $who, $mpi_data, MPI_COMM_WORLD);
		    
		    my @locs = @{$res_loc[$who]};
		    $res_loc[$who] = undef;
		    
		    #if primary node has chunk result to send then send them
		    while (defined(my $loc = shift @locs)){
			if ($loc == $root){
			    my $res = shift @{$c_results[$who]};
			    print "COMM HAVE C_RESULT\t|  SND2\t|  mpi_data (c_res frm root)\t|  $rank\t-->\t$who\n" if($main::debug);
			    MPI_SendII(\$res, $who, $mpi_data, MPI_COMM_WORLD);
			}
		    }
		}
		#no one has anything yet
		else{
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  c_res_status (no_c_res)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$no_c_res, 1, MPI_INT, $who, $c_res_status, MPI_COMM_WORLD);
		}
		
		#continue the rest if the node needs a helper
		if($what == $need_helper){
		    #find the number of helpers required
		    my $num_helpers_req;
		    print "HELPER/RESULT REQUESTED\t|  RECV\t|  work_order (num_helpers_req)\t|  $rank\t<--\t$who\n" if($main::debug);
		    MPI_Recv(\$num_helpers_req, 1, MPI_INT, $who, $work_order, MPI_COMM_WORLD);
		    
		    #number of secondary node helpers available
		    my $sec_node_avail = @limbo_stack;
		    
		    #number of primary node threads available
		    my $thr_avail = ($t_need_flag == 2 && ! defined $t_chunk) ? 1 : 0;
		    
		    #signal that no helpers are available
		    if($sec_node_avail == 0 && $thr_avail == 0){
			print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (no_helpers_avail)\t|  $rank\t-->\t$who\n" if($main::debug);
			MPI_Send(\$no_helper, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD);
		    }
		    else{ #if node helpers are available
			#helpers to send
			my $helpers = [];
			
			#secondary node helpers
			if($sec_node_avail > 0){
			    #seperate the helpers
			    while(@{$helpers} < $num_helpers_req && @limbo_stack > 0){
				my $helper = shift @limbo_stack;
				$active[$helper] = -1 - $who; #indicates who they work for
				push(@{$helpers}, $helper);
			    }
			    
			    $num_helpers_req -= @{$helpers};
			}
			
			#primary node thread helper
			my $root_helper_flag = 0;
			if ($thr_avail && $num_helpers_req > 0){
			    my $helper = $root;
			    $active[$root] = -1 - $who; #indicates who they work for
			    #aways make root node first
			    unshift(@{$helpers}, $helper);
			    $root_helper_flag = 1;
			}
			
			#say help is available and send ids of the helpers
			print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (yes_helpers_avail)\t|  $rank\t-->\t$who\n" if($main::debug);
			MPI_Send(\$yes_helper, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD);
			print "HELPER/RESULT REQUESTED\t|  SND2\t|  mpi_data (helper_loc_list)\t|  $rank\t-->\t$who\n" if($main::debug);
			MPI_SendII(\$helpers, $who, $mpi_data, MPI_COMM_WORLD);
			
			#take chunk as a helper
			if($root_helper_flag){
			    #see who's one who needs help
			    my $who2;
			    print "HELPER/RESULT REQUESTED\t|  RECV\t|  who_I_am (for root)\t|  $rank\t<--\t$who2\n" if($main::debug);
			    MPI_Recv(\$who2, 1,  MPI_INT, $who, $who_I_am, MPI_COMM_WORLD);
			    
			    #get go_chunk request_status
			    my $req_stat;
			    print "HELPER/RESULT REQUESTED\t|  RECV\t|  req_stat (is chunk? for root)\t|  $rank\t<--\t$who2\n" if($main::debug);
			    MPI_Recv(\$req_stat, 1, MPI_INT, $who2, $request_status, MPI_COMM_WORLD );
			    if ($req_stat == $go_chunk){
				#get the chunk
				my $chnk;
				print "HELPER/RESULT REQUESTED\t|  RCV2\t|  mpi_data (chunk for root)\t|  $rank\t<--\t$who2\n" if($main::debug);
				MPI_RecvII(\$chnk, $who2, $mpi_data, MPI_COMM_WORLD, 1);
				$t_need_flag = 0;
				$t_chunk = $chnk;
			    }
			    elsif($req_stat == $reset){
				$t_need_flag = 2;
			    }
			    else{
				die "ERROR: Logic error in getting chunk as a helper\n";
			    }
			}

			#signal to limbo nodes to become a helper
			foreach my $helper (@$helpers){
			    next if($helper == $root); #skip root

			    #turn node into helper node
			    print "HELPER/RESULT REQUESTED\t|  RECV\t|  who_I_am (clr nd)\t\t|  $rank\t<--\t$helper\n" if($main::debug);
			    MPI_Recv(\$empty, 1,  MPI_INT, $helper, $who_I_am, MPI_COMM_WORLD); #clear who I am response
			    print "HELPER/RESULT REQUESTED\t|  RECV\t|  what_I_want (clr nd)\t\t|  $rank\t<--\t$helper\n" if($main::debug);
			    MPI_Recv(\$empty, 1, MPI_INT, $helper, $what_I_want, MPI_COMM_WORLD); #clear what I want response
			    print "HELPER/RESULT REQUESTED\t|  RECV\t|  result_status (clr nd)\t|  $rank\t<--\t$helper\n" if($main::debug);
			    MPI_Recv(\$empty, 1,  MPI_INT, $helper, $result_status, MPI_COMM_WORLD); #clear result status response
			    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (wait_as_helper nd)\t|  $rank\t-->\t$helper\n" if($main::debug);
			    MPI_Send(\$wait_as_helper, 1, MPI_INT, $helper, $request_status, MPI_COMM_WORLD); #signal to become helper
			}
		    }
		}
	    }
	    #if the node has a chunk result, do this
	    elsif($what == $have_c_res){
		#get the owner of the result
		my $owner;
		print "COMM HAVE C_RESULT\t|  RECV\t|  work_order (res own fr root)\t|  $rank\t<--\t$who\n" if($main::debug);
		MPI_Recv(\$owner, 1, MPI_INT, $who, $work_order, MPI_COMM_WORLD);

		if($owner == $root){ #if root is owner get result
		    my $chunk_res;
		    print "COMM HAVE C_RESULT\t|  RCV2\t|  mpi_data (c_res for root)\t|  $rank\t<--\t$who\n" if($main::debug);
		    MPI_RecvII(\$chunk_res, $who, $mpi_data, MPI_COMM_WORLD, 1); #get chunk result
		    print "COMM HAVE C_RESULT\t|  SEND\t|  who_I_am (for reset from root)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$root, 1,  MPI_INT, $who, $who_I_am, MPI_COMM_WORLD); #tell helper node who I am
		    print "COMM HAVE C_RESULT\t|  SEND\t|  req_stat (reset from root)\t|  $rank\t-->\t$who\n" if($main::debug);
		    MPI_Send(\$reset, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD); #reset node (no chunk)
		    push(@returned_chunks, $chunk_res);
		}
		else{ #take note of owner to tell him he has a result waiting
		    push(@{$res_loc[$owner]}, $who);
		}
	    }
	    #if what the node wants is something else
	    else{
		die "ERROR: Invalid request type\n";
	    }
	}
	
	#see if all contigs are finished
	$go_mpi_status = 0;
	if(! $iterator->finished || @failed > 0 || @interrupted > 0){
	    $go_mpi_status = 1;
	}
	else{
	    foreach my $n (@active){
		if((defined($n) && $n != 0)){
		    $go_mpi_status = 1;
		    last;
		}
	    }
	}
    }
    
    #---tell mpi nodes to terminate
    for(my $i = 1; $i < $size; $i++){
	print "TERMINATION\t|  RECV\t|  who_I_am (clr)\t\t|  $rank\t<--\t$i\n" if($main::debug);
	MPI_Recv(\$empty, 1,  MPI_INT, $i, $who_I_am, MPI_COMM_WORLD); #clear who I am response
	print "TERMINATION\t|  RECV\t|  what_I_want (clr)\t|  $rank\t<--\t$i\n" if($main::debug);
	MPI_Recv(\$empty, 1, MPI_INT, $i, $what_I_want, MPI_COMM_WORLD); #clear what I want response
	print "TERMINATION\t|  RECV\t|  result_status (clr)\t|  $rank\t<--\t$i\n" if($main::debug);
	MPI_Recv(\$empty, 1,  MPI_INT, $i, $result_status, MPI_COMM_WORLD); #clear result status response
	print "TERMINATION\t|  SEND\t|  req_stat (terminate)\t|  $rank\t-->\t$i\n" if($main::debug);
	MPI_Send(\$terminate, 1, MPI_INT, $i, $request_status, MPI_COMM_WORLD); #signal to become helper
    }
    
    #---release thread
    $t_terminate = 1; #signals to thread to clean up
    $thr->detach() unless(!$thr || $thr->is_detached);
    
    print STDERR "\n\nMaker is now finished!!!\n\n";
}
#------SECONDARY MPI PROCESSES------
else {
    my $go_mpi_status = 1;
    my $tier_result;
    my $tier;
    my $chunk_result;
    my $be_helper;

    #--receive control files from root
    my $CTL_OPT;
    print "INITIALIZE CTL_OPT\t|  RCV2\t|  mpi_data (ctl_opt)\t|  $rank\t<--\t$root\n" if($main::debug);
    MPI_RecvII(\$CTL_OPT, $root, $mpi_data, MPI_COMM_WORLD);

    #---set up blast databases and indexes for analyisis
    $CTL_OPT->{_not_root} = 1;
    if($rank < 5){ #only first 5 so as not to overdo it
	GI::create_blastdb($CTL_OPT);
	GI::build_all_indexes($CTL_OPT);
    }
    #set to true for threads false for no threads
    $t_need_flag = ($main::no_threads) ? 0 : 1;
    my $thr = threads->create(\&node_thread) if($t_need_flag);    

    while ($go_mpi_status) {
	#====INTERNAL CHUNK THREAD
	#check on results from internal thread
	if (defined($t_chunk_result)){
	    my $c_res =  ${thaw($t_chunk_result)};
	    $t_chunk_result = undef;
	    $tier->update_chunk($c_res);
	    $tier->run();
	    next;
	}
	#====END THREAD
	
	#decide what this node needs
	my $what;
	my $chunk;

	if(defined $chunk_result){
	    #NOTE: $be_helper is set to true here
	    $what = $have_c_res;
	}
	elsif($be_helper){
	    #see who needs help
	    my $who;
	    print "HELPER/RESULT REQUESTED\t|  RECV\t|  who_I_am (for no-root)\t|  $rank\t<--\tANY\n" if($main::debug);
	    MPI_Recv(\$who, 1,  MPI_INT, -2, $who_I_am, MPI_COMM_WORLD);

	    #get request_status for chunk (was chunk available?)
	    my $chunk_status;
	    print "HELPER/RESULT REQUESTED\t|  RECV\t|  req_stat (is_chunk? no-root)\t|  $rank\t<--\t$who\n" if($main::debug);
	    MPI_Recv(\$chunk_status, 1, MPI_INT, $who, $request_status, MPI_COMM_WORLD );

	    #if there is a chunk do this
	    if($chunk_status == $go_chunk){
		#get chunk to process
		my $chnk;
		print "HELPER/RESULT REQUESTED\t|  RCV2\t|  mpi_data (chunk for no-root)\t|  $rank\t<--\t$who\n" if($main::debug);
		MPI_RecvII(\$chnk, $who, $mpi_data, MPI_COMM_WORLD);

		#run chunk
		$chnk->run($rank);
		$chunk_result = $chnk;
		next;
	    }
	    #if the reset signal is received do this
	    elsif($chunk_status == $reset){
		$be_helper = 0;
		next;
	    }
	    #if the terminate signal is received do this
	    elsif($chunk_status == $terminate){
		$go_mpi_status = 0;
		last;
	    }
	    else{
		die "ERROR: Invalid chunk status signal\n;";
	    }
	}
	elsif(!defined($tier) || $tier->terminated){
	    $what = $need_tier;
	    if(defined($tier)){
		#collect errors and failures if any
		$tier_result->{-error} = $tier->error;
		$tier_result->{-failed} = $tier->failed;
		$tier_result->{-interrupt} = $tier->interrupt if(!$tier->{_seen});
		$tier_result->{-fasta} = $tier->fasta if($tier->failed || $tier_result->{-interrupt});
		$tier = undef;
	    }
	}
	elsif(($tier->chunk_total_count == 1) && ($tier->num_chunks == 1)){
	    #run lonesome chunk (should never happen but it's here just in case)
	    my $r_chunk = $tier->next_chunk; #running chunk
	    $chunk = undef; #just incase
	    $r_chunk->run($rank);
	    $tier->update_chunk($r_chunk);
	    $tier->run();
	    next;
	}
	elsif(($tier->result_count == $tier->chunk_total_count - 1) && ($tier->num_chunks == 1)){
	    #run last chunk outside of thread
	    my $r_chunk = $tier->next_chunk; #running chunk
	    $chunk = undef; #just incase
	    $r_chunk->run($rank);
	    $tier->update_chunk($r_chunk);
	    $tier->run();
	    next;
	}
	elsif($thr && !$t_need_flag && ($tier->result_count == $tier->chunk_total_count - 1)){
	    #waiting on thread
	    sleep 1;
	    next;
	}
	elsif(($tier->num_chunks > 1) || ($thr && !$t_need_flag && $tier->num_chunks > 0)){
	    $chunk = $tier->next_chunk if(!$thr || $t_need_flag);
	    $what = $need_helper;
	}
	elsif($tier->result_count < $tier->chunk_total_count){
	    $chunk = $tier->next_chunk if(!$thr || $t_need_flag);
	    $what = $need_c_res;
	}
	else{
	    $tier->run();
	    next;
	}

	#tell the  primary process what node it is speaking to
	print "COMM INITIALIZATION\t|  SEND\t|  who_I_am\t\t\t|  $rank\t-->\t$root\n" if($main::debug);
	MPI_Send(\$rank, 1, MPI_INT, $root, $who_I_am, MPI_COMM_WORLD );
		
	#--tell primary node what this node needs
	print "COMM INITIALIZATION\t|  SEND\t|  what_I_want\t\t\t|  $rank\t-->\t$root\n" if($main::debug);
	MPI_Send(\$what, 1, MPI_INT, $root, $what_I_want, MPI_COMM_WORLD );
	
	#if what I want is a tier do this
	if($what == $need_tier){
	    #Send result status
	    my $rs_type = (defined($tier_result)) ? $yes_result: $no_result;
	    my $stat = (defined($tier_result)) ? "yes_result": "no_result" if($main::debug);
	    print "COMM TIER REQUESTED\t|  SEND\t|  result_status ($stat)\t|  $rank\t-->\t$root\n" if($main::debug);
	    MPI_Send(\$rs_type, 1, MPI_INT, $root, $result_status, MPI_COMM_WORLD );
	    
	    #Send result if available
	    if($rs_type == $yes_result){
		print "COMM TIER REQUESTED\t|  SND2\t|  mpi_data (tier_result)\t|  $rank\t-->\t$root\n" if($main::debug);
		MPI_SendII(\$tier_result, $root, $mpi_data, MPI_COMM_WORLD);
		$tier_result = undef;
	    }
	    
	    #get request_status for the tier
	    my $req_status;
	    print "COMM TIER REQUESTED\t|  RECV\t|  req_stat (is tier?)\t\t|  $rank\t<--\t$root\n" if($main::debug);
	    MPI_Recv(\$req_status, 1, MPI_INT, $root, $request_status, MPI_COMM_WORLD);
	    
	    #get tier and run if it if there is one
	    if($req_status == $yes_tier){
		print "COMM TIER REQUESTED\t|  RCV2\t|  mpi_data (tier)\t\t|  $rank\t<--\t$root\n" if($main::debug);
		MPI_RecvII(\$tier, $root, $mpi_data, MPI_COMM_WORLD);
		$tier->run;
		next;
	    }
	    #just wait and then try again later
	    elsif($req_status == $wait_ask_again){
		sleep 1;
		next;
	    }
	    #reset signal received
	    elsif($req_status == $reset){
		$be_helper = 0;
		next;
	    }
	    #wait as helper if asked to (blocks with MPI_Recv)
	    elsif($req_status == $wait_as_helper){
		$be_helper = 1;
		next
	    }
	    #termination signal received
	    elsif($req_status == $terminate){
		$go_mpi_status = 0;
                last;
	    }
	    else{
		die "ERROR: Invalid request status type\n";
	    }

	    next;
	} #if what I want is help or the result from a helper do this
	elsif ($what == $need_helper || $what == $need_c_res){
	    #give chunk to thread
	    if($thr && defined($chunk) && $tier->chunk_total_count > 1){
		$t_need_flag = 0;
		$t_chunk = freeze(\$chunk);
		$chunk = undef;
	    }

	    #check c_result_status
	    my $c_res_stat;
	    print "COMM HAVE C_RESULT\t|  RECV\t|  c_res_status (is c_res?)\t|  $rank\t<--\t$root\n" if($main::debug);
	    MPI_Recv(\$c_res_stat, 1, MPI_INT, $root, $c_res_status, MPI_COMM_WORLD);
	    
	    #if there are chunk results, do this
	    my $locs = [];
	    if($c_res_stat == $yes_c_res){
		#get ids of nodes with chunk result
		print "HELPER/RESULT REQUESTED\t|  RCV2\t|  mpi_data (result_loc_list)\t|  $rank\t<--\t$root\n" if($main::debug);
		MPI_RecvII(\$locs, $root, $mpi_data, MPI_COMM_WORLD);
		
		#get chunk results from only the root node for now
		my @non;
		foreach my $loc (@{$locs}){
		    if ($loc != $root){
			push(@non, $loc);
			next;
		    }
		    my $c_res;
		    print "COMM HAVE C_RESULT\t|  RCV2\t|  mpi_data (c_res frm root)\t|  $rank\t<--\t$root\n" if($main::debug);
		    MPI_RecvII(\$c_res, $loc, $mpi_data, MPI_COMM_WORLD);
		    $tier->update_chunk($c_res);
		}
		$locs = \@non;
	    }
	    
	    #send off chunks if the node needs a helper
	    my $helpers = [];
	    if ($what == $need_helper){
		#send the number of helpers required
		my $num_helpers_req = ($tier->num_chunks - @$locs > 0) ? $tier->num_chunks - @$locs : 0;		
		print "HELPER/RESULT REQUESTED\t|  SEND\t|  work_order (num_helpers_req)\t|  $rank\t-->\t$root\n" if($main::debug);
		MPI_Send(\$num_helpers_req, 1, MPI_INT, $root, $work_order, MPI_COMM_WORLD);
		
		#see if helper is available
		my $help_stat;
		print "HELPER/RESULT REQUESTED\t|  RECV\t|  req_stat (is helper avail?)\t|  $rank\t<--\t$root\n" if($main::debug);
		MPI_Recv(\$help_stat, 1, MPI_INT, $root, $request_status, MPI_COMM_WORLD);
		
		if($help_stat == $yes_helper){
		    print "HELPER/RESULT REQUESTED\t|  RCV2\t|  mpi_data (helper_loc_list)\t|  $rank\t<--\t$root\n" if($main::debug);
		    MPI_RecvII(\$helpers, $root, $mpi_data, MPI_COMM_WORLD); #get helper ids
		}
	    }

	    #send chunk to helper
	    foreach my $helper (@{$helpers}){
		print "HELPER/RESULT REQUESTED\t|  SEND\t|  who_I_am (for *helpers)\t|  $rank\t-->\t$helper\n" if($main::debug);
		MPI_Send(\$rank, 1,  MPI_INT, $helper, $who_I_am, MPI_COMM_WORLD); #say I'm the one who needs help

		#send chunk if availabile
		if($tier->num_chunks > 0){
		    my $chnk = $tier->next_chunk;
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (go_chunk *helpers)\t|  $rank\t-->\t$helper\n" if($main::debug);
		    MPI_Send(\$go_chunk, 1, MPI_INT, $helper, $request_status, MPI_COMM_WORLD); #say chunk is available
		    print "HELPER/RESULT REQUESTED\t|  SND2\t|  mpi_data (chunk *helpers)\t|  $rank\t-->\t$helper\n" if($main::debug);
		    MPI_SendII(\$chnk, $helper, $mpi_data, MPI_COMM_WORLD); #send chunk
		}
		else{
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (reset *helpers)\t|  $rank\t-->\t$helper\n" if($main::debug);
		    MPI_Send(\$reset, 1, MPI_INT, $helper, $request_status, MPI_COMM_WORLD); #send reset signal
		}
	    }

	    #since root communication has terminated, get chunk results from non-root nodes
	    #and send them something else to do or release them
	    foreach my $loc (@{$locs}){
		#this shouldn't happen but just incase
		die "ERROR: Root has chunk result post-root communication" if ($loc == $root);

		my $c_res;
		print "COMM HAVE C_RESULT\t|  RCV2\t|  mpi_data (c_res no-root)\t|  $rank\t<--\t$loc\n" if($main::debug);
		MPI_RecvII(\$c_res, $loc, $mpi_data, MPI_COMM_WORLD);
		$tier->update_chunk($c_res);

		print "HELPER/RESULT REQUESTED\t|  SEND\t|  who_I_am (for xhelpers)\t|  $rank\t-->\t$loc\n" if($main::debug);
		MPI_Send(\$rank, 1,  MPI_INT, $loc, $who_I_am, MPI_COMM_WORLD); #restablish relationship

		#send something else or release helper
		if($tier->num_chunks > 0){
		    my $chnk = $tier->next_chunk;
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (go_chunk xhelpers)\t|  $rank\t-->\t$loc\n" if($main::debug);
                    MPI_Send(\$go_chunk, 1, MPI_INT, $loc, $request_status, MPI_COMM_WORLD); #say chunk is available
		    print "HELPER/RESULT REQUESTED\t|  SND2\t|  mpi_data (chunk xhelpers)\t|  $rank\t-->\t$loc\n" if($main::debug);
                    MPI_SendII(\$chnk, $loc, $mpi_data, MPI_COMM_WORLD); #send chunk
		}
		else{
		    print "HELPER/RESULT REQUESTED\t|  SEND\t|  req_stat (reset xhelpers)\t|  $rank\t-->\t$loc\n" if($main::debug);
                    MPI_Send(\$reset, 1, MPI_INT, $loc, $request_status, MPI_COMM_WORLD); #send reset signal
		}
	    }

	    #nothing provided and nothing to advance to (wait)
	    if(!@{$helpers} && !@{$locs} && !$chunk && !$t_need_flag ){
		sleep 1;
	    }

	    #finally run local chunk if there is one
	    if(defined($chunk)){
		my $r_chunk = $chunk; #running chunk
		$chunk = undef;
		$r_chunk->run($rank);
		$tier->update_chunk($r_chunk);
	    }

	    $tier->run();
	    next;
	}
	#if just finished a helper chunk, inform that it is finished
	elsif($what == $have_c_res){
	    #send the owner id of the result
	    my $owner = $chunk_result->id();
	    ($owner) = split(":", $owner);
	    print "COMM HAVE C_RESULT\t|  SEND\t|  work_order (res own to root)\t|  $rank\t-->\t$root\n" if($main::debug);
	    MPI_Send(\$owner, 1, MPI_INT, $root, $work_order, MPI_COMM_WORLD);

	    #send the result
	    print "COMM HAVE C_RESULT\t|  SND2\t|  mpi_data (c_res frm no-root)\t|  $rank\t-->\t$owner\n" if($main::debug);
	    MPI_SendII(\$chunk_result, $owner, $mpi_data, MPI_COMM_WORLD);
	    $chunk_result = undef;

	    next;
	}
    }

    #---release thread
    $t_terminate = 1; #signals to thread to clean up
    $thr->detach() unless(!$thr || $thr->is_detached);
}

#---------ALL NODES----------
MPI_Finalize();			#terminate MPI

exit(0);

#-----------------------------------------------------------------------------
#----------------------------------- SUBS ------------------------------------
#-----------------------------------------------------------------------------
#other things for root node to do
#(thread allows root to process tiers like a secondary node)
sub node_thread {
   my $tier;
   my $chunk;

   if($main::no_threads){ #pause and return if no thread is needed
       $t_need_flag = 0;
       return;
   }

   $t_need_flag = 1;

   while(not $t_terminate){
      #load serialized tier into tier
      if(! defined ($tier) && defined ($t_tier)){
	 $t_need_flag = 0;
	 $tier = ${thaw($t_tier)};
	 $t_tier = undef;
	 next;
      }#process tier
      elsif(defined($tier)){
	 #get chunk results from other nodes
	 while(my $res = shift @returned_chunks){
	    $res = ${thaw($res)};
	    $tier->update_chunk($res);
	 }

	 #run the tier as far as possible
	 $tier->run;

	 #get all chunks available
	 my $chnk = $tier->next_chunk;
	 while(my $o_chnk = $tier->next_chunk){
	    $o_chnk = freeze(\$o_chnk);
	    push (@chunks, $o_chnk);
	 }

	 #run chunks one at a time
	 $chnk->run($rank) if ($chnk);
	 $tier->update_chunk($chnk) if ($chnk);
	 while($chnk = shift @chunks){
	    $chnk = ${thaw($chnk)};
	    if($tier->failed){ #skip chunks after failure
		$tier->update_chunk($chnk);
		next;
	    }

	    $chnk->run($rank);
	    $tier->update_chunk($chnk);
	 }

	 #let tier advance if possible
	 $tier->run();

	 #terminate tier, wait, or continue
	 if($tier->terminated){
	    my $tier_result;
	    $tier_result->{-error} = $tier->error;
	    $tier_result->{-failed} = $tier->failed;
	    $tier_result->{-interrupt} = $tier->interrupt if(!$tier->{_seen});
	    $tier_result->{-fasta} = $tier->fasta if ($tier->failed || $tier_result->{-interrupt});

	    sleep 1 while (defined ($t_tier_result)); #pause incase result will be overwritten
	    $t_tier_result = freeze(\$tier_result);
	    $tier = undef;
	    $t_need_flag = 1;
	 }#take a break
	 elsif($tier->num_chunks == 0){
	    #keeps thread from hogging resources while waiting for external results
	    sleep 1;
	 }

	 next;
      }#load serialized chunk into chunk
      elsif(! defined ($chunk) && defined ($t_chunk)){
	 $t_need_flag = 0;
	 $chunk = ${thaw($t_chunk)};
	 $t_chunk = undef;
	 next;
      }#process chunk
      elsif(defined($chunk)){
	 $chunk->run($rank);
	 sleep 1 while (defined ($t_chunk_result)); #pause incase result will be overwritten
	 $t_chunk_result = freeze(\$chunk);
	 $chunk = undef;
	 $t_need_flag = 1;
	 next;
      }#take a break
      else{
	 #keeps thread form hogging resources when there is nothing to do
	 sleep 1;
      }
   }
}
#----------------------------------------------------------------------------
#easy dump of string to a tempfile
sub totemp{
   my $data = shift @_;

   my ($fh, $name) = tempfile();
   print $fh $data;
   close ($fh);

   return $name;
}
#----------------------------------------------------------------------------
#sends scalar variable contents via serialization
#scalar can hold ref to other data structures
sub MPI_SendII{
   my $msg = shift @_;
   my $target = shift @_;
   my $tag = shift @_;
   my $communicator = shift @_;
   my $no_freeze = shift @_;

   my $send = ($no_freeze) ? $msg : \ (freeze($msg));
   my $length = length($$send);
   
   MPI_Send(\$length, 1, MPI_INT, $target, $message_length, $communicator);
   MPI_Send($send, $length, MPI_CHAR, $target, $tag, $communicator);   
}
#----------------------------------------------------------------------------
#receives serialized scalar variable
#scalar can hold ref to other data structures
sub MPI_RecvII{
   my $ref = shift @_;
   my $source = shift @_;
   my $tag = shift @_;
   my $communicator = shift @_;
   my $no_thaw = shift @_;

   my $recv;
   my $length;

   MPI_Recv(\$length, 1, MPI_INT, $source, $message_length, $communicator);
   MPI_Recv(\$recv, $length, MPI_CHAR, $source, $tag, $communicator); #receive line

   ${$ref} = ($no_thaw) ? $recv : ${thaw($recv)};
}
